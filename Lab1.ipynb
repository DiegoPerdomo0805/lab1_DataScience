{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. El ancho (tamaño de la capa escondida) del algoritmo. Intenten con un tamaño de 200.  ¿Cómo cambia la precisión de validación del modelo?  ¿Cuánto tiempo se tardó el algoritmo en entrenar?  ¿Puede encontrar un tamaño de capa escondida que funcione mejor?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Código"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos_mnist, info_mnist = tfds.load(name='mnist',\n",
    "                                    shuffle_files = False,\n",
    "                                    with_info=True, \n",
    "                                    as_supervised=True)\n",
    "\n",
    "entreno_mnist, prueba_mnist = datos_mnist['train'], datos_mnist['test']\n",
    "num_obs_validacion = 0.1 * info_mnist.splits['train'].num_examples\n",
    "num_obs_validacion = tf.cast(num_obs_validacion, tf.int64)\n",
    "num_obs_prueba = info_mnist.splits['test'].num_examples\n",
    "num_obs_prueba = tf.cast(num_obs_prueba, tf.int64)\n",
    "\n",
    "def normalizar(imagen, etiqueta):\n",
    "    imagen = tf.cast(imagen, tf.float32)\n",
    "    imagen /= 255.\n",
    "    return imagen, etiqueta\n",
    "\n",
    "datos_entrenamiento_y_validacion_normalizados = entreno_mnist.map(normalizar)\n",
    "datos_prueba = prueba_mnist.map(normalizar)\n",
    "TAMANIO_BUFFER = 10000\n",
    "datos_entrenamiento_y_validacion_barajeados = datos_entrenamiento_y_validacion_normalizados.shuffle(TAMANIO_BUFFER)\n",
    "datos_validacion = datos_entrenamiento_y_validacion_barajeados.take(num_obs_validacion)\n",
    "datos_entreno = datos_entrenamiento_y_validacion_barajeados.skip(num_obs_validacion)\n",
    "TAMANIO_TANDA = 100\n",
    "\n",
    "datos_entreno = datos_entreno.batch(TAMANIO_TANDA)\n",
    "\n",
    "datos_validacion = datos_validacion.batch(num_obs_validacion)\n",
    "\n",
    "datos_prueba = datos_prueba.batch(num_obs_prueba)\n",
    "entradas_validacion, metas_validacion = next(iter(datos_validacion))\n",
    "\n",
    "tamanio_entrada = 784\n",
    "tamanio_salida = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "tamanio_capa_escondida = 200\n",
    "modelo = tf.keras.Sequential([\n",
    "\n",
    "    tf.keras.layers.Flatten(input_shape=(28, 28, 1)), # capa entrada\n",
    "    \n",
    "    tf.keras.layers.Dense(tamanio_capa_escondida, activation='relu'), # 1era capa escondida\n",
    "    tf.keras.layers.Dense(tamanio_capa_escondida, activation='relu'), # 2nda capa escondida\n",
    "\n",
    "    tf.keras.layers.Dense(tamanio_salida, activation='softmax') # capa salida\n",
    "])\n",
    "\n",
    "modelo.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "NUMERO_EPOCAS = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "540/540 - 3s - loss: 0.2748 - accuracy: 0.9223 - val_loss: 0.1219 - val_accuracy: 0.9643 - 3s/epoch - 6ms/step\n",
      "Epoch 2/5\n",
      "540/540 - 2s - loss: 0.1059 - accuracy: 0.9677 - val_loss: 0.0787 - val_accuracy: 0.9762 - 2s/epoch - 4ms/step\n",
      "Epoch 3/5\n",
      "540/540 - 2s - loss: 0.0711 - accuracy: 0.9783 - val_loss: 0.0570 - val_accuracy: 0.9830 - 2s/epoch - 4ms/step\n",
      "Epoch 4/5\n",
      "540/540 - 2s - loss: 0.0529 - accuracy: 0.9832 - val_loss: 0.0595 - val_accuracy: 0.9820 - 2s/epoch - 4ms/step\n",
      "Epoch 5/5\n",
      "540/540 - 2s - loss: 0.0393 - accuracy: 0.9879 - val_loss: 0.0412 - val_accuracy: 0.9862 - 2s/epoch - 4ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x24e06ec27d0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelo.fit(datos_entreno, \n",
    "          epochs = NUMERO_EPOCAS, \n",
    "          validation_data = (entradas_validacion, metas_validacion),\n",
    "          validation_steps = 10,\n",
    "          verbose = 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 310ms/step - loss: 0.0709 - accuracy: 0.9797\n",
      "Pérdida de prueba: 0.07. Precisión de prueba: 97.97%\n"
     ]
    }
   ],
   "source": [
    "perdida_prueba, precision_prueba = modelo.evaluate(datos_prueba)\n",
    "# Si se desea, se puede aplicar un formateo \"bonito\"\n",
    "print('Pérdida de prueba: {0:.2f}. Precisión de prueba: {1:.2f}%'.format(perdida_prueba, precision_prueba * 100.))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Respuestas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* La precisión aumentó ligeramente, ahora con un valor de 97.99 en vez de 96.73.\n",
    "* El algoritmo se tardó 13.2 segundos en ser entrenado\n",
    "* Encontrar un tamaño de capa escondida óptimo es un proceso de prueba y error, por lo que se puede tardar mucho tiempo en encontrar el tamaño óptimo. Se intentaron con valores entre 350 y 200, pero no se encontró un valor que mejorara la precisión de manera considerable y de manera consistente. El valor que más se acercó fue 256, con una precisión de 98.82, pero no se pudo replicar el resultado, por lo que no se considera como un valor óptimo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. La profundidad del algoritmo.  Agreguen una capa escondida más al algoritmo. Este es un ejercicio extremadamente importante!  ¿Cómo cambia la precisión de validación?  ¿Qué hay del tiempo que se tarda en ejecutar? Pista: deben tener cuidado con las formas de los pesos y los sesgos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Código"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos_mnist, info_mnist = tfds.load(name='mnist',\n",
    "                                    shuffle_files = False,\n",
    "                                    with_info=True, \n",
    "                                    as_supervised=True)\n",
    "\n",
    "entreno_mnist, prueba_mnist = datos_mnist['train'], datos_mnist['test']\n",
    "num_obs_validacion = 0.1 * info_mnist.splits['train'].num_examples\n",
    "num_obs_validacion = tf.cast(num_obs_validacion, tf.int64)\n",
    "num_obs_prueba = info_mnist.splits['test'].num_examples\n",
    "num_obs_prueba = tf.cast(num_obs_prueba, tf.int64)\n",
    "\n",
    "def normalizar(imagen, etiqueta):\n",
    "    imagen = tf.cast(imagen, tf.float32)\n",
    "    imagen /= 255.\n",
    "    return imagen, etiqueta\n",
    "\n",
    "datos_entrenamiento_y_validacion_normalizados = entreno_mnist.map(normalizar)\n",
    "datos_prueba = prueba_mnist.map(normalizar)\n",
    "TAMANIO_BUFFER = 10000\n",
    "datos_entrenamiento_y_validacion_barajeados = datos_entrenamiento_y_validacion_normalizados.shuffle(TAMANIO_BUFFER)\n",
    "datos_validacion = datos_entrenamiento_y_validacion_barajeados.take(num_obs_validacion)\n",
    "datos_entreno = datos_entrenamiento_y_validacion_barajeados.skip(num_obs_validacion)\n",
    "TAMANIO_TANDA = 100\n",
    "\n",
    "datos_entreno = datos_entreno.batch(TAMANIO_TANDA)\n",
    "\n",
    "datos_validacion = datos_validacion.batch(num_obs_validacion)\n",
    "\n",
    "datos_prueba = datos_prueba.batch(num_obs_prueba)\n",
    "entradas_validacion, metas_validacion = next(iter(datos_validacion))\n",
    "\n",
    "tamanio_entrada = 784\n",
    "tamanio_salida = 10\n",
    "tamanio_capa_escondida = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(28, 28, 1)),\n",
    "    tf.keras.layers.Dense(tamanio_capa_escondida, activation='relu'),\n",
    "    tf.keras.layers.Dense(tamanio_capa_escondida, activation='relu'),\n",
    "    tf.keras.layers.Dense(tamanio_capa_escondida, activation='relu'),  # Nueva capa\n",
    "    tf.keras.layers.Dense(tamanio_salida, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "540/540 - 6s - loss: 0.2597 - accuracy: 0.9241 - val_loss: 0.1339 - val_accuracy: 0.9598 - 6s/epoch - 11ms/step\n",
      "Epoch 2/5\n",
      "540/540 - 3s - loss: 0.1013 - accuracy: 0.9691 - val_loss: 0.0871 - val_accuracy: 0.9752 - 3s/epoch - 6ms/step\n",
      "Epoch 3/5\n",
      "540/540 - 3s - loss: 0.0680 - accuracy: 0.9788 - val_loss: 0.0719 - val_accuracy: 0.9780 - 3s/epoch - 6ms/step\n",
      "Epoch 4/5\n",
      "540/540 - 3s - loss: 0.0516 - accuracy: 0.9840 - val_loss: 0.0624 - val_accuracy: 0.9812 - 3s/epoch - 6ms/step\n",
      "Epoch 5/5\n",
      "540/540 - 3s - loss: 0.0410 - accuracy: 0.9865 - val_loss: 0.0453 - val_accuracy: 0.9858 - 3s/epoch - 6ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x24e06e0b220>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelo.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "NUMERO_EPOCAS = 5\n",
    "\n",
    "modelo.fit(datos_entreno, \n",
    "          epochs = NUMERO_EPOCAS, \n",
    "          validation_data = (entradas_validacion, metas_validacion),\n",
    "          validation_steps = 10,\n",
    "          verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 906ms/step - loss: 0.0723 - accuracy: 0.9785\n",
      "Pérdida de prueba: 0.07. Precisión de prueba: 97.85%\n"
     ]
    }
   ],
   "source": [
    "perdida_prueba, precision_prueba = modelo.evaluate(datos_prueba)\n",
    "print('Pérdida de prueba: {0:.2f}. Precisión de prueba: {1:.2f}%'.format(perdida_prueba, precision_prueba * 100.))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Respuestas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* El valor de la precisión bajó ligeramente, pero sigue siendo muy alto, por lo que no se ve afectado el modelo.\n",
    "* Por otro lado, el tiempo de entrenamiento aumentó considerablemente, tomando en cuenta que originalmente este tomaba cerca de 13 segundos, ahora toma casi 19 segundos; un aumento de casi el 50%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. El ancho y la profundidad del algoritmo.  Agregue cuantas capas sean necesarias para llegar a 5 capas escondidas.  Es más, ajusten el ancho del algoritmo conforme lo encuentre más conveniente.  ¿Cómo cambia la precisión de validación? ¿Qué hay del tiempo de ejecución?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Código"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos_mnist, info_mnist = tfds.load(name='mnist',\n",
    "                                    shuffle_files = False,\n",
    "                                    with_info=True, \n",
    "                                    as_supervised=True)\n",
    "\n",
    "entreno_mnist, prueba_mnist = datos_mnist['train'], datos_mnist['test']\n",
    "num_obs_validacion = 0.1 * info_mnist.splits['train'].num_examples\n",
    "num_obs_validacion = tf.cast(num_obs_validacion, tf.int64)\n",
    "num_obs_prueba = info_mnist.splits['test'].num_examples\n",
    "num_obs_prueba = tf.cast(num_obs_prueba, tf.int64)\n",
    "\n",
    "def normalizar(imagen, etiqueta):\n",
    "    imagen = tf.cast(imagen, tf.float32)\n",
    "    imagen /= 255.\n",
    "    return imagen, etiqueta\n",
    "\n",
    "datos_entrenamiento_y_validacion_normalizados = entreno_mnist.map(normalizar)\n",
    "datos_prueba = prueba_mnist.map(normalizar)\n",
    "TAMANIO_BUFFER = 10000\n",
    "datos_entrenamiento_y_validacion_barajeados = datos_entrenamiento_y_validacion_normalizados.shuffle(TAMANIO_BUFFER)\n",
    "datos_validacion = datos_entrenamiento_y_validacion_barajeados.take(num_obs_validacion)\n",
    "datos_entreno = datos_entrenamiento_y_validacion_barajeados.skip(num_obs_validacion)\n",
    "TAMANIO_TANDA = 100\n",
    "\n",
    "datos_entreno = datos_entreno.batch(TAMANIO_TANDA)\n",
    "\n",
    "datos_validacion = datos_validacion.batch(num_obs_validacion)\n",
    "\n",
    "datos_prueba = datos_prueba.batch(num_obs_prueba)\n",
    "entradas_validacion, metas_validacion = next(iter(datos_validacion))\n",
    "\n",
    "tamanio_entrada = 784\n",
    "tamanio_salida = 10\n",
    "tamanio_capa_escondida = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(28, 28, 1)),\n",
    "    tf.keras.layers.Dense(256, activation='relu'),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(256, activation='relu'),\n",
    "    tf.keras.layers.Dense(tamanio_salida, activation='softmax')\n",
    "])\n",
    "\n",
    "modelo.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "NUMERO_EPOCAS = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "540/540 - 6s - loss: 0.0450 - accuracy: 0.9857 - val_loss: 0.0412 - val_accuracy: 0.9873 - 6s/epoch - 11ms/step\n",
      "Epoch 2/5\n",
      "540/540 - 5s - loss: 0.0343 - accuracy: 0.9894 - val_loss: 0.0442 - val_accuracy: 0.9867 - 5s/epoch - 10ms/step\n",
      "Epoch 3/5\n",
      "540/540 - 5s - loss: 0.0338 - accuracy: 0.9897 - val_loss: 0.0332 - val_accuracy: 0.9900 - 5s/epoch - 10ms/step\n",
      "Epoch 4/5\n",
      "540/540 - 7s - loss: 0.0285 - accuracy: 0.9913 - val_loss: 0.0359 - val_accuracy: 0.9888 - 7s/epoch - 13ms/step\n",
      "Epoch 5/5\n",
      "540/540 - 7s - loss: 0.0277 - accuracy: 0.9913 - val_loss: 0.0381 - val_accuracy: 0.9895 - 7s/epoch - 13ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x24e1109db40>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelo.fit(datos_entreno, \n",
    "          epochs = NUMERO_EPOCAS, \n",
    "          validation_data = (entradas_validacion, metas_validacion),\n",
    "          validation_steps = 10,\n",
    "          verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 940ms/step - loss: 0.0952 - accuracy: 0.9779\n",
      "Pérdida de prueba: 0.10. Precisión de prueba: 97.79%\n"
     ]
    }
   ],
   "source": [
    "perdida_prueba, precision_prueba = modelo.evaluate(datos_prueba)\n",
    "print('Pérdida de prueba: {0:.2f}. Precisión de prueba: {1:.2f}%'.format(perdida_prueba, precision_prueba * 100.))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Respuestas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* La eficiencia no mejoró fuertemente, por más cambios y experimentos que se hicieron en cuanto al ancho de las capas. \n",
    "* El tiempo de ejecucuión dobló el valor original, por lo que no se considera una mejora."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Experimenten con las funciones de activación.  Intenten aplicar una transformación sigmoidal a ambas capas.  La activación sigmoidal se obtiene escribiendo “sigmoid”."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Código"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos_mnist, info_mnist = tfds.load(name='mnist',\n",
    "                                    shuffle_files = False,\n",
    "                                    with_info=True, \n",
    "                                    as_supervised=True)\n",
    "\n",
    "entreno_mnist, prueba_mnist = datos_mnist['train'], datos_mnist['test']\n",
    "num_obs_validacion = 0.1 * info_mnist.splits['train'].num_examples\n",
    "num_obs_validacion = tf.cast(num_obs_validacion, tf.int64)\n",
    "num_obs_prueba = info_mnist.splits['test'].num_examples\n",
    "num_obs_prueba = tf.cast(num_obs_prueba, tf.int64)\n",
    "\n",
    "def normalizar(imagen, etiqueta):\n",
    "    imagen = tf.cast(imagen, tf.float32)\n",
    "    imagen /= 255.\n",
    "    return imagen, etiqueta\n",
    "\n",
    "datos_entrenamiento_y_validacion_normalizados = entreno_mnist.map(normalizar)\n",
    "datos_prueba = prueba_mnist.map(normalizar)\n",
    "TAMANIO_BUFFER = 10000\n",
    "datos_entrenamiento_y_validacion_barajeados = datos_entrenamiento_y_validacion_normalizados.shuffle(TAMANIO_BUFFER)\n",
    "datos_validacion = datos_entrenamiento_y_validacion_barajeados.take(num_obs_validacion)\n",
    "datos_entreno = datos_entrenamiento_y_validacion_barajeados.skip(num_obs_validacion)\n",
    "TAMANIO_TANDA = 100\n",
    "\n",
    "datos_entreno = datos_entreno.batch(TAMANIO_TANDA)\n",
    "\n",
    "datos_validacion = datos_validacion.batch(num_obs_validacion)\n",
    "\n",
    "datos_prueba = datos_prueba.batch(num_obs_prueba)\n",
    "entradas_validacion, metas_validacion = next(iter(datos_validacion))\n",
    "\n",
    "tamanio_entrada = 784\n",
    "tamanio_salida = 10\n",
    "tamanio_capa_escondida = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(28, 28, 1)),\n",
    "    tf.keras.layers.Dense(tamanio_capa_escondida, activation='sigmoid'),  # Cambio a sigmoid\n",
    "    tf.keras.layers.Dense(tamanio_salida, activation='softmax')\n",
    "])\n",
    "modelo.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "NUMERO_EPOCAS = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "540/540 - 4s - loss: 0.5191 - accuracy: 0.8713 - val_loss: 0.2950 - val_accuracy: 0.9198 - 4s/epoch - 8ms/step\n",
      "Epoch 2/5\n",
      "540/540 - 3s - loss: 0.2573 - accuracy: 0.9269 - val_loss: 0.2242 - val_accuracy: 0.9393 - 3s/epoch - 5ms/step\n",
      "Epoch 3/5\n",
      "540/540 - 3s - loss: 0.2016 - accuracy: 0.9422 - val_loss: 0.1854 - val_accuracy: 0.9485 - 3s/epoch - 5ms/step\n",
      "Epoch 4/5\n",
      "540/540 - 3s - loss: 0.1681 - accuracy: 0.9517 - val_loss: 0.1579 - val_accuracy: 0.9580 - 3s/epoch - 5ms/step\n",
      "Epoch 5/5\n",
      "540/540 - 3s - loss: 0.1404 - accuracy: 0.9599 - val_loss: 0.1352 - val_accuracy: 0.9628 - 3s/epoch - 5ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x24e1269dd20>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelo.fit(datos_entreno, \n",
    "          epochs = NUMERO_EPOCAS, \n",
    "          validation_data = (entradas_validacion, metas_validacion),\n",
    "          validation_steps = 10,\n",
    "          verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 458ms/step - loss: 0.1351 - accuracy: 0.9604\n",
      "Pérdida de prueba: 0.14. Precisión de prueba: 96.04%\n"
     ]
    }
   ],
   "source": [
    "perdida_prueba, precision_prueba = modelo.evaluate(datos_prueba)\n",
    "print('Pérdida de prueba: {0:.2f}. Precisión de prueba: {1:.2f}%'.format(perdida_prueba, precision_prueba * 100.))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Respuestas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* El valor de la precisión empezó muy bajo, pero a medida que se fue entrenando la red, el valor de la precisión fue aumentando, hasta llegar a un valor de 0.96, lo cual es un muy buen valor, pero no es el mejor que se ha obtenido."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Continúen experimentando con las funciones de activación.  Intenten aplicar un ReLu a la primera capa escondida y tanh a la segunda.  La activación tanh se obtiene escribiendo “tanh”."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Código"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos_mnist, info_mnist = tfds.load(name='mnist',\n",
    "                                    shuffle_files = False,\n",
    "                                    with_info=True, \n",
    "                                    as_supervised=True)\n",
    "\n",
    "entreno_mnist, prueba_mnist = datos_mnist['train'], datos_mnist['test']\n",
    "num_obs_validacion = 0.1 * info_mnist.splits['train'].num_examples\n",
    "num_obs_validacion = tf.cast(num_obs_validacion, tf.int64)\n",
    "num_obs_prueba = info_mnist.splits['test'].num_examples\n",
    "num_obs_prueba = tf.cast(num_obs_prueba, tf.int64)\n",
    "\n",
    "def normalizar(imagen, etiqueta):\n",
    "    imagen = tf.cast(imagen, tf.float32)\n",
    "    imagen /= 255.\n",
    "    return imagen, etiqueta\n",
    "\n",
    "datos_entrenamiento_y_validacion_normalizados = entreno_mnist.map(normalizar)\n",
    "datos_prueba = prueba_mnist.map(normalizar)\n",
    "TAMANIO_BUFFER = 10000\n",
    "datos_entrenamiento_y_validacion_barajeados = datos_entrenamiento_y_validacion_normalizados.shuffle(TAMANIO_BUFFER)\n",
    "datos_validacion = datos_entrenamiento_y_validacion_barajeados.take(num_obs_validacion)\n",
    "datos_entreno = datos_entrenamiento_y_validacion_barajeados.skip(num_obs_validacion)\n",
    "TAMANIO_TANDA = 100\n",
    "\n",
    "datos_entreno = datos_entreno.batch(TAMANIO_TANDA)\n",
    "\n",
    "datos_validacion = datos_validacion.batch(num_obs_validacion)\n",
    "\n",
    "datos_prueba = datos_prueba.batch(num_obs_prueba)\n",
    "entradas_validacion, metas_validacion = next(iter(datos_validacion))\n",
    "\n",
    "tamanio_entrada = 784\n",
    "tamanio_salida = 10\n",
    "tamanio_capa_escondida = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(28, 28, 1)),\n",
    "    tf.keras.layers.Dense(tamanio_capa_escondida, activation='relu'),\n",
    "    tf.keras.layers.Dense(tamanio_capa_escondida, activation='tanh'),  # Cambio a tanh\n",
    "    tf.keras.layers.Dense(tamanio_salida, activation='softmax')\n",
    "])\n",
    "modelo.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "NUMERO_EPOCAS = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "540/540 - 7s - loss: 0.2557 - accuracy: 0.9255 - val_loss: 0.1373 - val_accuracy: 0.9598 - 7s/epoch - 14ms/step\n",
      "Epoch 2/5\n",
      "540/540 - 5s - loss: 0.1002 - accuracy: 0.9697 - val_loss: 0.0813 - val_accuracy: 0.9752 - 5s/epoch - 9ms/step\n",
      "Epoch 3/5\n",
      "540/540 - 4s - loss: 0.0660 - accuracy: 0.9795 - val_loss: 0.0613 - val_accuracy: 0.9810 - 4s/epoch - 8ms/step\n",
      "Epoch 4/5\n",
      "540/540 - 4s - loss: 0.0469 - accuracy: 0.9855 - val_loss: 0.0569 - val_accuracy: 0.9823 - 4s/epoch - 6ms/step\n",
      "Epoch 5/5\n",
      "540/540 - 3s - loss: 0.0351 - accuracy: 0.9893 - val_loss: 0.0421 - val_accuracy: 0.9867 - 3s/epoch - 6ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x24e12660df0>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelo.fit(datos_entreno, \n",
    "          epochs = NUMERO_EPOCAS, \n",
    "          validation_data = (entradas_validacion, metas_validacion),\n",
    "          validation_steps = 10,\n",
    "          verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 704ms/step - loss: 0.0708 - accuracy: 0.9783\n",
      "Pérdida de prueba: 0.07. Precisión de prueba: 97.83%\n"
     ]
    }
   ],
   "source": [
    "perdida_prueba, precision_prueba = modelo.evaluate(datos_prueba)\n",
    "print('Pérdida de prueba: {0:.2f}. Precisión de prueba: {1:.2f}%'.format(perdida_prueba, precision_prueba * 100.))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Respuestas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Este acercamiento tiene un muy bajo valor de pérdida y un alto valor de precisión, por lo que se considera que utilizar tangente hiperbólica como función de activación, junto con ReLU, es una buena opción para este problema."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Ajusten el tamaño de la tanda.  Prueben con un tamaño de tanda de 10,000. ¿Cómo cambia el tiempo requerido?  ¿Cómo cambia la precisión?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Código"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos_mnist, info_mnist = tfds.load(name='mnist',\n",
    "                                    shuffle_files = False,\n",
    "                                    with_info=True, \n",
    "                                    as_supervised=True)\n",
    "\n",
    "entreno_mnist, prueba_mnist = datos_mnist['train'], datos_mnist['test']\n",
    "num_obs_validacion = 0.1 * info_mnist.splits['train'].num_examples\n",
    "num_obs_validacion = tf.cast(num_obs_validacion, tf.int64)\n",
    "num_obs_prueba = info_mnist.splits['test'].num_examples\n",
    "num_obs_prueba = tf.cast(num_obs_prueba, tf.int64)\n",
    "\n",
    "def normalizar(imagen, etiqueta):\n",
    "    imagen = tf.cast(imagen, tf.float32)\n",
    "    imagen /= 255.\n",
    "    return imagen, etiqueta\n",
    "\n",
    "datos_entrenamiento_y_validacion_normalizados = entreno_mnist.map(normalizar)\n",
    "datos_prueba = prueba_mnist.map(normalizar)\n",
    "TAMANIO_BUFFER = 10000\n",
    "datos_entrenamiento_y_validacion_barajeados = datos_entrenamiento_y_validacion_normalizados.shuffle(TAMANIO_BUFFER)\n",
    "datos_validacion = datos_entrenamiento_y_validacion_barajeados.take(num_obs_validacion)\n",
    "datos_entreno = datos_entrenamiento_y_validacion_barajeados.skip(num_obs_validacion)\n",
    "TAMANIO_TANDA = 10000\n",
    "\n",
    "datos_entreno = datos_entreno.batch(TAMANIO_TANDA)\n",
    "\n",
    "datos_validacion = datos_validacion.batch(num_obs_validacion)\n",
    "\n",
    "datos_prueba = datos_prueba.batch(num_obs_prueba)\n",
    "entradas_validacion, metas_validacion = next(iter(datos_validacion))\n",
    "\n",
    "tamanio_entrada = 784\n",
    "tamanio_salida = 10\n",
    "tamanio_capa_escondida = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo = tf.keras.Sequential([\n",
    "\n",
    "    tf.keras.layers.Flatten(input_shape=(28, 28, 1)), # capa entrada\n",
    "    \n",
    "    tf.keras.layers.Dense(tamanio_capa_escondida, activation='relu'), # 1era capa escondida\n",
    "    tf.keras.layers.Dense(tamanio_capa_escondida, activation='relu'), # 2nda capa escondida\n",
    "\n",
    "    tf.keras.layers.Dense(tamanio_salida, activation='softmax') # capa salida\n",
    "])\n",
    "\n",
    "modelo.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "NUMERO_EPOCAS = 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 - 4s - loss: 1.9456 - accuracy: 0.4706 - val_loss: 1.3710 - val_accuracy: 0.7242 - 4s/epoch - 691ms/step\n",
      "Epoch 2/5\n",
      "6/6 - 1s - loss: 1.0834 - accuracy: 0.7710 - val_loss: 0.7020 - val_accuracy: 0.8340 - 1s/epoch - 238ms/step\n",
      "Epoch 3/5\n",
      "6/6 - 2s - loss: 0.5887 - accuracy: 0.8486 - val_loss: 0.4589 - val_accuracy: 0.8692 - 2s/epoch - 252ms/step\n",
      "Epoch 4/5\n",
      "6/6 - 1s - loss: 0.4196 - accuracy: 0.8780 - val_loss: 0.3730 - val_accuracy: 0.8875 - 1s/epoch - 235ms/step\n",
      "Epoch 5/5\n",
      "6/6 - 1s - loss: 0.3529 - accuracy: 0.8970 - val_loss: 0.3282 - val_accuracy: 0.9037 - 1s/epoch - 241ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x24e16aa2d70>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelo.fit(datos_entreno, \n",
    "          epochs = NUMERO_EPOCAS, \n",
    "          validation_data = (entradas_validacion, metas_validacion),\n",
    "          validation_steps = 10,\n",
    "          verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 649ms/step - loss: 0.3205 - accuracy: 0.9100\n",
      "Pérdida de prueba: 0.32. Precisión de prueba: 91.00%\n"
     ]
    }
   ],
   "source": [
    "perdida_prueba, precision_prueba = modelo.evaluate(datos_prueba)\n",
    "print('Pérdida de prueba: {0:.2f}. Precisión de prueba: {1:.2f}%'.format(perdida_prueba, precision_prueba * 100.))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Respuestas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* El tiempo de ejecución se encuentra cerca del valor original, con un valor un poco menor, por lo que se considera un acrecamiento más rápido que el original.\n",
    "* Por otro lado, la precisión cayó un 6%, lo más que ha caído en cualquiera de las otras configuraciones probadas. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Ajusten el tamaño de la tanda a 1.  Eso corresponde al SGD. ¿Cómo cambian el tiempo y la precisión?  ¿Es el resultado coherente con la teoría?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Código"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos_mnist, info_mnist = tfds.load(name='mnist',\n",
    "                                    shuffle_files = False,\n",
    "                                    with_info=True, \n",
    "                                    as_supervised=True)\n",
    "\n",
    "entreno_mnist, prueba_mnist = datos_mnist['train'], datos_mnist['test']\n",
    "num_obs_validacion = 0.1 * info_mnist.splits['train'].num_examples\n",
    "num_obs_validacion = tf.cast(num_obs_validacion, tf.int64)\n",
    "num_obs_prueba = info_mnist.splits['test'].num_examples\n",
    "num_obs_prueba = tf.cast(num_obs_prueba, tf.int64)\n",
    "\n",
    "def normalizar(imagen, etiqueta):\n",
    "    imagen = tf.cast(imagen, tf.float32)\n",
    "    imagen /= 255.\n",
    "    return imagen, etiqueta\n",
    "\n",
    "datos_entrenamiento_y_validacion_normalizados = entreno_mnist.map(normalizar)\n",
    "datos_prueba = prueba_mnist.map(normalizar)\n",
    "TAMANIO_BUFFER = 10000\n",
    "datos_entrenamiento_y_validacion_barajeados = datos_entrenamiento_y_validacion_normalizados.shuffle(TAMANIO_BUFFER)\n",
    "datos_validacion = datos_entrenamiento_y_validacion_barajeados.take(num_obs_validacion)\n",
    "datos_entreno = datos_entrenamiento_y_validacion_barajeados.skip(num_obs_validacion)\n",
    "TAMANIO_TANDA = 1\n",
    "\n",
    "datos_entreno = datos_entreno.batch(TAMANIO_TANDA)\n",
    "\n",
    "datos_validacion = datos_validacion.batch(num_obs_validacion)\n",
    "\n",
    "datos_prueba = datos_prueba.batch(num_obs_prueba)\n",
    "entradas_validacion, metas_validacion = next(iter(datos_validacion))\n",
    "\n",
    "tamanio_entrada = 784\n",
    "tamanio_salida = 10\n",
    "tamanio_capa_escondida = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo = tf.keras.Sequential([\n",
    "\n",
    "    tf.keras.layers.Flatten(input_shape=(28, 28, 1)), # capa entrada\n",
    "    \n",
    "    tf.keras.layers.Dense(tamanio_capa_escondida, activation='relu'), # 1era capa escondida\n",
    "    tf.keras.layers.Dense(tamanio_capa_escondida, activation='relu'), # 2nda capa escondida\n",
    "\n",
    "    tf.keras.layers.Dense(tamanio_salida, activation='softmax') # capa salida\n",
    "])\n",
    "\n",
    "modelo.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "NUMERO_EPOCAS = 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "54000/54000 - 186s - loss: 0.2566 - accuracy: 0.9289 - val_loss: 0.1901 - val_accuracy: 0.9548 - 186s/epoch - 3ms/step\n",
      "Epoch 2/5\n",
      "54000/54000 - 198s - loss: 0.1801 - accuracy: 0.9565 - val_loss: 0.1477 - val_accuracy: 0.9655 - 198s/epoch - 4ms/step\n",
      "Epoch 3/5\n",
      "54000/54000 - 270s - loss: 0.1640 - accuracy: 0.9632 - val_loss: 0.1553 - val_accuracy: 0.9690 - 270s/epoch - 5ms/step\n",
      "Epoch 4/5\n",
      "54000/54000 - 229s - loss: 0.1543 - accuracy: 0.9663 - val_loss: 0.1429 - val_accuracy: 0.9613 - 229s/epoch - 4ms/step\n",
      "Epoch 5/5\n",
      "54000/54000 - 192s - loss: 0.1442 - accuracy: 0.9696 - val_loss: 0.1539 - val_accuracy: 0.9677 - 192s/epoch - 4ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x24e1ee60670>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelo.fit(datos_entreno, \n",
    "          epochs = NUMERO_EPOCAS, \n",
    "          validation_data = (entradas_validacion, metas_validacion),\n",
    "          validation_steps = 10,\n",
    "          verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 769ms/step - loss: 0.2233 - accuracy: 0.9657\n",
      "Pérdida de prueba: 0.22. Precisión de prueba: 96.57%\n"
     ]
    }
   ],
   "source": [
    "perdida_prueba, precision_prueba = modelo.evaluate(datos_prueba)\n",
    "print('Pérdida de prueba: {0:.2f}. Precisión de prueba: {1:.2f}%'.format(perdida_prueba, precision_prueba * 100.))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Respuestas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* El tiempo es, por lejos, el más alto de todos los acercamientos. El tiempo fue más de 80 veces mayor que el del acercaiento original.\n",
    "* El valor de la precisión, por otro lado, no mejora mucho. El valor de la precisión es de 0.97 (aproximadamente), casi lo mismo que en el acercamiento original.\n",
    "* Sí, el resultado es coherente con la teoría del gradiente descendiente estocástico. Al reducir tanto el tamaño de la tanda, se puede lograr una mayor precisión, pero introduce mucho ruido en el proceso, por lo que el tiempo de ejecución es mucho mayor y el resultado no es mucho mejor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Ajusten la tasa de aprendizaje.  Prueben con un valor de 0.0001.  ¿Hace alguna diferencia?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Código"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos_mnist, info_mnist = tfds.load(name='mnist',\n",
    "                                    shuffle_files = False,\n",
    "                                    with_info=True, \n",
    "                                    as_supervised=True)\n",
    "\n",
    "entreno_mnist, prueba_mnist = datos_mnist['train'], datos_mnist['test']\n",
    "num_obs_validacion = 0.1 * info_mnist.splits['train'].num_examples\n",
    "num_obs_validacion = tf.cast(num_obs_validacion, tf.int64)\n",
    "num_obs_prueba = info_mnist.splits['test'].num_examples\n",
    "num_obs_prueba = tf.cast(num_obs_prueba, tf.int64)\n",
    "\n",
    "def normalizar(imagen, etiqueta):\n",
    "    imagen = tf.cast(imagen, tf.float32)\n",
    "    imagen /= 255.\n",
    "    return imagen, etiqueta\n",
    "\n",
    "datos_entrenamiento_y_validacion_normalizados = entreno_mnist.map(normalizar)\n",
    "datos_prueba = prueba_mnist.map(normalizar)\n",
    "TAMANIO_BUFFER = 10000\n",
    "datos_entrenamiento_y_validacion_barajeados = datos_entrenamiento_y_validacion_normalizados.shuffle(TAMANIO_BUFFER)\n",
    "datos_validacion = datos_entrenamiento_y_validacion_barajeados.take(num_obs_validacion)\n",
    "datos_entreno = datos_entrenamiento_y_validacion_barajeados.skip(num_obs_validacion)\n",
    "TAMANIO_TANDA = 100\n",
    "\n",
    "datos_entreno = datos_entreno.batch(TAMANIO_TANDA)\n",
    "\n",
    "datos_validacion = datos_validacion.batch(num_obs_validacion)\n",
    "\n",
    "datos_prueba = datos_prueba.batch(num_obs_prueba)\n",
    "entradas_validacion, metas_validacion = next(iter(datos_validacion))\n",
    "\n",
    "tamanio_entrada = 784\n",
    "tamanio_salida = 10\n",
    "tamanio_capa_escondida = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo = tf.keras.Sequential([\n",
    "\n",
    "    tf.keras.layers.Flatten(input_shape=(28, 28, 1)), # capa entrada\n",
    "    \n",
    "    tf.keras.layers.Dense(tamanio_capa_escondida, activation='relu'), # 1era capa escondida\n",
    "    tf.keras.layers.Dense(tamanio_capa_escondida, activation='relu'), # 2nda capa escondida\n",
    "\n",
    "    tf.keras.layers.Dense(tamanio_salida, activation='softmax') # capa salida\n",
    "])\n",
    "\n",
    "modelo.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001) , loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "NUMERO_EPOCAS = 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "540/540 - 9s - loss: 0.7265 - accuracy: 0.8199 - val_loss: 0.3280 - val_accuracy: 0.9042 - 9s/epoch - 16ms/step\n",
      "Epoch 2/5\n",
      "540/540 - 5s - loss: 0.2756 - accuracy: 0.9235 - val_loss: 0.2401 - val_accuracy: 0.9333 - 5s/epoch - 9ms/step\n",
      "Epoch 3/5\n",
      "540/540 - 5s - loss: 0.2188 - accuracy: 0.9393 - val_loss: 0.1934 - val_accuracy: 0.9440 - 5s/epoch - 9ms/step\n",
      "Epoch 4/5\n",
      "540/540 - 5s - loss: 0.1817 - accuracy: 0.9477 - val_loss: 0.1702 - val_accuracy: 0.9492 - 5s/epoch - 9ms/step\n",
      "Epoch 5/5\n",
      "540/540 - 5s - loss: 0.1579 - accuracy: 0.9542 - val_loss: 0.1515 - val_accuracy: 0.9543 - 5s/epoch - 9ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x24e1ee63040>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelo.fit(datos_entreno, \n",
    "          epochs = NUMERO_EPOCAS, \n",
    "          validation_data = (entradas_validacion, metas_validacion),\n",
    "          validation_steps = 10,\n",
    "          verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step - loss: 0.1536 - accuracy: 0.9548\n",
      "Pérdida de prueba: 0.15. Precisión de prueba: 95.48%\n"
     ]
    }
   ],
   "source": [
    "perdida_prueba, precision_prueba = modelo.evaluate(datos_prueba)\n",
    "print('Pérdida de prueba: {0:.2f}. Precisión de prueba: {1:.2f}%'.format(perdida_prueba, precision_prueba * 100.))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Respuestas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Ya que la tasa de aprendizaje es muy pequeña, el ajuste toma más tiempo en converger. El tiempo es aproximadamente 2 veces mayor que el tiempo del acercamiento original. \n",
    "* En cuanto a temas de precisión, no se considera que haya una diferencia significativa entre ambos acercamientos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Ajusten la tasa de aprendizaje a 0.02.  ¿Hay alguna diferencia?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Código"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos_mnist, info_mnist = tfds.load(name='mnist',\n",
    "                                    shuffle_files = False,\n",
    "                                    with_info=True, \n",
    "                                    as_supervised=True)\n",
    "\n",
    "entreno_mnist, prueba_mnist = datos_mnist['train'], datos_mnist['test']\n",
    "num_obs_validacion = 0.1 * info_mnist.splits['train'].num_examples\n",
    "num_obs_validacion = tf.cast(num_obs_validacion, tf.int64)\n",
    "num_obs_prueba = info_mnist.splits['test'].num_examples\n",
    "num_obs_prueba = tf.cast(num_obs_prueba, tf.int64)\n",
    "\n",
    "def normalizar(imagen, etiqueta):\n",
    "    imagen = tf.cast(imagen, tf.float32)\n",
    "    imagen /= 255.\n",
    "    return imagen, etiqueta\n",
    "\n",
    "datos_entrenamiento_y_validacion_normalizados = entreno_mnist.map(normalizar)\n",
    "datos_prueba = prueba_mnist.map(normalizar)\n",
    "TAMANIO_BUFFER = 10000\n",
    "datos_entrenamiento_y_validacion_barajeados = datos_entrenamiento_y_validacion_normalizados.shuffle(TAMANIO_BUFFER)\n",
    "datos_validacion = datos_entrenamiento_y_validacion_barajeados.take(num_obs_validacion)\n",
    "datos_entreno = datos_entrenamiento_y_validacion_barajeados.skip(num_obs_validacion)\n",
    "TAMANIO_TANDA = 100\n",
    "\n",
    "datos_entreno = datos_entreno.batch(TAMANIO_TANDA)\n",
    "\n",
    "datos_validacion = datos_validacion.batch(num_obs_validacion)\n",
    "\n",
    "datos_prueba = datos_prueba.batch(num_obs_prueba)\n",
    "entradas_validacion, metas_validacion = next(iter(datos_validacion))\n",
    "\n",
    "tamanio_entrada = 784\n",
    "tamanio_salida = 10\n",
    "tamanio_capa_escondida = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo = tf.keras.Sequential([\n",
    "\n",
    "    tf.keras.layers.Flatten(input_shape=(28, 28, 1)), # capa entrada\n",
    "    \n",
    "    tf.keras.layers.Dense(tamanio_capa_escondida, activation='relu'), # 1era capa escondida\n",
    "    tf.keras.layers.Dense(tamanio_capa_escondida, activation='relu'), # 2nda capa escondida\n",
    "\n",
    "    tf.keras.layers.Dense(tamanio_salida, activation='softmax') # capa salida\n",
    "])\n",
    "\n",
    "modelo.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.2) , loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "NUMERO_EPOCAS = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "540/540 - 7s - loss: 6.9588 - accuracy: 0.1418 - val_loss: 2.2806 - val_accuracy: 0.1158 - 7s/epoch - 14ms/step\n",
      "Epoch 2/5\n",
      "540/540 - 4s - loss: 2.1904 - accuracy: 0.1637 - val_loss: 2.1023 - val_accuracy: 0.1882 - 4s/epoch - 8ms/step\n",
      "Epoch 3/5\n",
      "540/540 - 4s - loss: 2.1004 - accuracy: 0.1843 - val_loss: 2.0783 - val_accuracy: 0.1918 - 4s/epoch - 7ms/step\n",
      "Epoch 4/5\n",
      "540/540 - 4s - loss: 2.2288 - accuracy: 0.1345 - val_loss: 2.3247 - val_accuracy: 0.0967 - 4s/epoch - 7ms/step\n",
      "Epoch 5/5\n",
      "540/540 - 4s - loss: 2.3163 - accuracy: 0.1029 - val_loss: 2.3143 - val_accuracy: 0.1025 - 4s/epoch - 7ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x24e1efd1510>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelo.fit(datos_entreno, \n",
    "          epochs = NUMERO_EPOCAS, \n",
    "          validation_data = (entradas_validacion, metas_validacion),\n",
    "          validation_steps = 10,\n",
    "          verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 772ms/step - loss: 2.3125 - accuracy: 0.1028\n",
      "Pérdida de prueba: 2.31. Precisión de prueba: 10.28%\n"
     ]
    }
   ],
   "source": [
    "perdida_prueba, precision_prueba = modelo.evaluate(datos_prueba)\n",
    "print('Pérdida de prueba: {0:.2f}. Precisión de prueba: {1:.2f}%'.format(perdida_prueba, precision_prueba * 100.))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Respuestas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Con un valor de 0.2 en la tasa de aprendizaje, el desempeño del modelo es muy malo, con una precisión de 10% en la validación. Esto se debe a que el modelo no logra converger a un mínimo local, por lo que no logra aprender nada."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Combinen todos los métodos indicados arriba e intenten llegar a una precisión de validación de 98.5% o más."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Código"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos_mnist, info_mnist = tfds.load(name='mnist',\n",
    "                                    shuffle_files = False,\n",
    "                                    with_info=True, \n",
    "                                    as_supervised=True)\n",
    "\n",
    "entreno_mnist, prueba_mnist = datos_mnist['train'], datos_mnist['test']\n",
    "num_obs_validacion = 0.1 * info_mnist.splits['train'].num_examples\n",
    "num_obs_validacion = tf.cast(num_obs_validacion, tf.int64)\n",
    "num_obs_prueba = info_mnist.splits['test'].num_examples\n",
    "num_obs_prueba = tf.cast(num_obs_prueba, tf.int64)\n",
    "\n",
    "def normalizar(imagen, etiqueta):\n",
    "    imagen = tf.cast(imagen, tf.float32)\n",
    "    imagen /= 255.\n",
    "    return imagen, etiqueta\n",
    "\n",
    "datos_entrenamiento_y_validacion_normalizados = entreno_mnist.map(normalizar)\n",
    "datos_prueba = prueba_mnist.map(normalizar)\n",
    "TAMANIO_BUFFER = 10000\n",
    "datos_entrenamiento_y_validacion_barajeados = datos_entrenamiento_y_validacion_normalizados.shuffle(TAMANIO_BUFFER)\n",
    "datos_validacion = datos_entrenamiento_y_validacion_barajeados.take(num_obs_validacion)\n",
    "datos_entreno = datos_entrenamiento_y_validacion_barajeados.skip(num_obs_validacion)\n",
    "TAMANIO_TANDA = 25\n",
    "\n",
    "datos_entreno = datos_entreno.batch(TAMANIO_TANDA)\n",
    "\n",
    "datos_validacion = datos_validacion.batch(num_obs_validacion)\n",
    "\n",
    "datos_prueba = datos_prueba.batch(num_obs_prueba)\n",
    "entradas_validacion, metas_validacion = next(iter(datos_validacion))\n",
    "\n",
    "tamanio_entrada = 784\n",
    "tamanio_salida = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(28, 28, 1)),\n",
    "    tf.keras.layers.Dense(256, activation='relu'),\n",
    "    tf.keras.layers.Dense(128, activation='tanh'),\n",
    "    tf.keras.layers.Dense(192, activation='sigmoid'),\n",
    "    #tf.keras.layers.Dense(tamanio_capa_escondida, activation='relu'),\n",
    "    #tf.keras.layers.Dense(tamanio_capa_escondida, activation='tanh'),\n",
    "    #tf.keras.layers.Dense(tamanio_capa_escondida, activation='sigmoid'),\n",
    "    tf.keras.layers.Dense(tamanio_salida, activation='softmax')\n",
    "])\n",
    "modelo.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0005) , loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "NUMERO_EPOCAS = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2160/2160 - 12s - loss: 0.2701 - accuracy: 0.9238 - val_loss: 0.1337 - val_accuracy: 0.9613 - 12s/epoch - 6ms/step\n",
      "Epoch 2/5\n",
      "2160/2160 - 10s - loss: 0.0970 - accuracy: 0.9708 - val_loss: 0.1040 - val_accuracy: 0.9690 - 10s/epoch - 5ms/step\n",
      "Epoch 3/5\n",
      "2160/2160 - 11s - loss: 0.0638 - accuracy: 0.9805 - val_loss: 0.0673 - val_accuracy: 0.9797 - 11s/epoch - 5ms/step\n",
      "Epoch 4/5\n",
      "2160/2160 - 11s - loss: 0.0475 - accuracy: 0.9853 - val_loss: 0.0540 - val_accuracy: 0.9865 - 11s/epoch - 5ms/step\n",
      "Epoch 5/5\n",
      "2160/2160 - 10s - loss: 0.0360 - accuracy: 0.9887 - val_loss: 0.0601 - val_accuracy: 0.9838 - 10s/epoch - 5ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x24e21508580>"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelo.fit(datos_entreno, \n",
    "          epochs = NUMERO_EPOCAS, \n",
    "          validation_data = (entradas_validacion, metas_validacion),\n",
    "          validation_steps = 10,\n",
    "          verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 779ms/step - loss: 0.0812 - accuracy: 0.9771\n",
      "Pérdida de prueba: 0.08. Precisión de prueba: 97.71%\n"
     ]
    }
   ],
   "source": [
    "perdida_prueba, precision_prueba = modelo.evaluate(datos_prueba)\n",
    "print('Pérdida de prueba: {0:.2f}. Precisión de prueba: {1:.2f}%'.format(perdida_prueba, precision_prueba * 100.))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Respuestas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Después de múltiples intentos con diferentes acercamientos, utilizando cambios en las funciones de activación, el ancho de las capas, el número de capas, el tamaño de la tanda y la tasa de aprendizaje, el valor que más se acercó fue 97.71% con una tasa de aprendizaje de 0.0005, 3 capas ocultas de tamaños variados, tres funciones de activación diferentes y un tamaño de tanda de 25.\n",
    "* No se pudo llegar al 98.5% de precisión, pero se logró un 97.71% con una tasa de aprendizaje de 0.0005, 3 capas ocultas de tamaños variados, tres funciones de activación diferentes y un tamaño de tanda de 25."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
